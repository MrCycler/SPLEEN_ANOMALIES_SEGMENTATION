# SEGMENTACIN DE IMGENES DE BAZOS PARA LA DETECCIN DE TUMORES

## Datos del curso 

 **Proyecto final**
* **Curso: Computaci贸n Gr谩fica**
* **Clase del 2020-1**
* **Maestr铆a en inform谩tica - Menci贸n en ciencias de la computaci贸n**

## Resumen 
La detecci贸n de tumores en radiograf铆as, siempre ha sido un desaf铆o para las redes actuales que buscan la segmentaci贸n de este tipo de im谩genes, actualmente existen investigaciones de segmentaci贸n en escala de grises. Esta investigaci贸n propone una segmentaci贸n a colores, para la detecci贸n de posibles tumores en la imagen. Para lograr esto se procesa las im谩genes de Bazos obtenidos de "Medical Segmentation Decathlon" y se hace uso del modelo ResNet152 pre-entrenada en escala de grises para la clasificaci贸n de mamograf铆as. Nuestro m茅todo propuesto puede segmentar las im谩genes a colores con cierto porcentaje de ruido. Mostramos que tambi茅n se puede realizar segmentaci贸n a color de im谩genes m茅dicas en base a modelos pre entrenados en escala de grises.

<p align="center"> 
    <img src='Results/loss_curva.png' alt="Resultado">
</p>

## Arquitectura y estructura de archivos 

El proyecto cuentas con las siguientes carpetas:

 Visualization ([Ver](/Visualization)) .- Contiene los scripts para para extraer las im谩genes de cortes de las ecograf铆as del dataset original [MedicalSegmentationDecathlon](http://medicaldecathlon.com/). Para el proyecto en particular se escog铆o la partici贸n del dataset que corresponde a ecograf铆as de bazos [SpleenDataset](https://drive.google.com/file/d/1jzeNU1EKnK81PyTsrx0ujfNl-t0Jo8uE/view?usp=sharing).

<div align="center"> 
    <h5>Imagen correspondiente al dataset original</h1>
    <img src='Set%20Generation/resultados/prueba.png' alt="Prueba" height="200px" width="200px">
</div>

 Set Generation ([Ver](/Set%20Generation)) .- Contienen los scripts hechos en jupyter notebooks para generar el set de entrenamiento compuesto de im谩genes originales e im谩genes etiquetadas. Se destacan las funciones para el etiquetado de im谩genes que utiliza la librer铆a [OpenCV](https://opencv.org/). El etiquetado autom谩tico simula el etiquetado realizado por especialistas en un eventual proyecto similar destinado a producci贸n.

<div align="center"> 
    <h5>Imagen original</h5>
    <img src='Set%20Generation/resultados/spleen_2.ni_z068.png' alt="Original" height="200px" width="200px">
</div>

<div align="center"> 
    <h5>Imagen etiquetada</h5>
    <img src='Set%20Generation/resultados/label_spleen_2.ni_z068.png' alt="Labelled" height="200px" width="200px">
</div>

 Data .- En esta carpeta se recomienda almacenar los siguientes archivos : 
- Im谩genes del set de entrenamiento [Descargar](https://drive.google.com/file/d/12ELJm48gudZApmxozqqeg4JL5HInDauU/view?usp=sharing)
- Im谩genes del set de v谩lidacion [Descargar](https://drive.google.com/file/d/12KR_l0TgLhwc3J25GFUkd9S73OEtphG_/view?usp=sharing)
- Im谩genes etiquetadas del set de entrenamiento [Descargar](https://drive.google.com/file/d/12N6rBvzncffWGx2AjtJ8BAgPw4lQ__xz/view?usp=sharing)
- Modelo preentrenado en el proyecto [Descargar](https://drive.google.com/file/d/1vlLGX3Lx8q-rH-rxNqVvxRKNWaSxn9i9/view?usp=sharing)

 Training ([Ver](/Training)) .- Contienen los experimentos hechos en jupyter notebooks donde se va construyendo y definiendo nuestro modelo final. El script donde se define nuestro modelo final puede ser accedido en el siguiente [Enlace](/Training/Entrenamiento_Images_v3(FINAL).ipynb). Nuestro modelo final tiene como base un modelo preentrenado ResNet152 que puede ser descargado del siguiente [Enlace](http://data.csail.mit.edu/places/medical/pretrained/2class/resnet152/checkpoint_00000005.pth.tar) y corresponde al proyecto [DDSM-VISUAL-PRIMITIVES](https://github.com/jimmyyhwu/ddsm-visual-primitives). Nuestro proyecto amplia la red neuronal preentrenada de modo que en base a las im谩genes originales de ecograf铆as en blanco y negro se generen las im谩genes etiquetadas de forma similar a las etiquetadas correspondientes. A continuaci贸n se muestra los resultados: 

<div align="center"> 
    <h5>Imagen dada al modelo</h5>
    <img src='Results/in2.png' alt="In" height="200px" width="200px">
</div>

<div align="center"> 
    <h5>Imagen obtenida como resultado tras 1 茅poca</h5>
    <img src='Results/med.png' alt="Med" height="200px" width="200px">
</div>

<div align="center"> 
    <h5>Imagen obtenida como resultado tras 3 茅pocas</h5>
    <img src='Results/out2.png' alt="Out" height="200px" width="200px">
</div>

 Results ([Ver](/Results)) .- En esta carpeta se almacenan las im谩genes que se obtuvieron como resultado de los experimentos y el script de visualizaci贸n de los resultados finales que se puede ver en el siguiente [Enlace](/Results/Resultados.ipynb). Nuestro modelo final se carga de la nube.

## Pasos para la ejecuci贸n (Jupyther Notebook - Colab) 

- Copiar el archivo (XYZ.ipynb) correspondiente a cualquier cuaderno que quiera ejecutar a Google Drive.
- Abrir el archivo con la herramienta COLAB.
- Activamos el GPU dentro de la herramienta.
- Ejecutar el cuardeno (El archivo debe ya contar con las fases de descarga y descompresi贸n de datasets y modelos usados por los cuadernos).

## Autores 

<div align="center"> 
    <img src='https://dci.pucp.edu.pe/wp-content/uploads/2014/02/logo-negro-pucp.jpg' alt="Resultado">
    <h1>ESCUELA DE POSGRADO</h1>
</div>

* **Jose Ulises Morales Pariona** - [Github](https://github.com/ulises968)

* **Juan Manuel Mendoza Jacinto** - [Linkedin](https://pe.linkedin.com/in/juan-manuel-mendoza-jacinto-18515ab0) - [Github](https://github.com/fararay)

* **Alex Blainer Sanchez Sanchez** - [Linkedin](https://www.linkedin.com/in/alex-sanchez-sanchez/?originalSubdomain=pe) - [Github](https://github.com/alexssanchez)

## Licencia 

La licencia de este proyecto es del tipo **GNU General Public License v3.0** ([Ver](LICENSE.md))


